Our model relies on four different data types: text description, the videoâ€™s hashtags, the sound attached, and the video itself. We created a sub-model or introduced logic for each data type before combining all the sub-model outputs that were trained separately into one vector and passed it through a fully connected network. For the text description, we built an attention-based LSTM taking the input words of the description represented as the vector given by [AraVec 3.0 (word2vec)](https://github.com/bakrianoo/aravec). As for the hashtags, we developed a weighted-KNN model. Our methodology was to look at the correlation between a given hashtag and the nationalistic spirit of the posts tagged by it. We then defined a score function combining the hashtags of each post (similar to a weighted-KNN). Our video model is the Tannet model provided by [MMaction 2.0](https://github.com/open-mmlab/mmaction2/blob/master/configs/recognition/tanet/README.md), with it\'s final layer cut to allow our final model to infer more about the video itself. Finally, we created a list based on the nationalistic sounds we accumulated in the tagging process for the video's audio and looked for those sounds in future posts. Combining those four, we created our final model, which outputs a nationalistic score for a given TikTok post.
